{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_hhZAAZzpIT"
   },
   "source": [
    "## Homework Grading\n",
    "The goal of this is to develop a robust homework grading system which combines Google Colab + Jupyter Notebooks + GitHub Classroom. \n",
    "\n",
    "For this example, we are going to download a zip file with a sample assignments.  However, if you end up grading from colab, you may consider directly mounting your google drive with the code below.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30806,
     "status": "ok",
     "timestamp": 1569159478196,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA3rVQCA8Cvb_ag0a37NtL0nadMqx5jcT3eM5bn0g=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "bfxNKE1kzuCa",
    "outputId": "3f95c0ca-971b-4e5b-f9cf-5c11590deabb"
   },
   "outputs": [],
   "source": [
    "#This is used when grading from Colab. \n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#!ls -al /content/drive/'My Drive'/autograding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This installs the forked version of Gopher Grader. \n",
    "#!pip install git+https://github.com/CarmeLabs/Gofer-Grader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set to what you want to grade\n",
    "course = 'introml'\n",
    "assignment = 'assignment1' \n",
    "  #use sample for a demo assignment or assignment name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup for Grading\n",
    "\n",
    "Make sure you have installed the dependencies in the `requirements.txt` file. \n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "Make sure you have all of the required files.\n",
    "\n",
    "1.  Download assignment from github and put it in the `assignments/<course>/<assignment>\n",
    "2. Update the `/config/<course>.ini` file with the appropriate assignment file. \n",
    "3. Verify that the appropriate tests and data are in the associated `/tests/<course>/assignment` folder. \n",
    "4. Verify that the roster is setup in `roster/course.xlsx`. \n",
    "5. Verify other configurations in  `/config/<course>.ini` are correct.  \n",
    "\n",
    "If you want to delete the tmp grading folder set `delete_tmp` to `True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_tmp = False\n",
    "\n",
    "#TBD. Do a check which prechecks for \n",
    "#the existance of all required files as stated above. \n",
    "#Give option to delete the /tmp folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set and Load the Configuration\n",
    "We save configuration in a local file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjZgEPpP61tb"
   },
   "outputs": [],
   "source": [
    "#Set configuration\n",
    "from pathlib import Path\n",
    "import configparser, sys, os, importlib\n",
    "import pandas as pd\n",
    " \n",
    "cwd_dir = Path.cwd() #For running locally\n",
    "base_dir = cwd_dir.parent #For running locally\n",
    "#base_dir='/content/drive/My Drive/autograding'\n",
    "course_file = course+'.ini'  #config file \n",
    "config_file = base_dir / 'config' / course_file\n",
    "modules_path = base_dir / 'modules' \n",
    "sys.path.append('../modules') # Not sure why appending the mudles path didn't work. \n",
    "\n",
    "#Load the autograding library\n",
    "import autograde as ag\n",
    "importlib.reload(ag)\n",
    "\n",
    "#read in the configuration\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "cf = ag.set_config(course, assignment, base_dir, config)\n",
    "cf\n",
    "#cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grade Students\n",
    "\n",
    "This `ag.grade` function is used to grade students. This will copy from the directory found in the config settings to the /tmp directory. \n",
    "\n",
    "`cf`   # This is the config. \n",
    "\n",
    "`grade` # The number of students to grade.  Usually I start with a few. \n",
    "\n",
    "`cleanup` # This will delete the temp directory when done.\n",
    "\n",
    "`regrade` # This will regrade students or no. \n",
    "\n",
    "`submissions` # This is a list of students to grade and can be used for selective regrading. \n",
    "\n",
    "This will generate output include:\n",
    "\n",
    "This function generates grading output in:\n",
    "`/output/<course>/<assignment>/` that includes a status, json output, and the executed notebooks. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48104,
     "status": "error",
     "timestamp": 1569006689710,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mA3rVQCA8Cvb_ag0a37NtL0nadMqx5jcT3eM5bn0g=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "-XGqSIXi61tg",
    "outputId": "7b32c84b-e3c2-4b88-ea92-b8a31006f71c"
   },
   "outputs": [],
   "source": [
    "#This generates grades as JSON \n",
    "importlib.reload(ag) #Reload model if working on it so that it can be reloaded.\n",
    "#Leave submissions blank to grade all submissions. \n",
    "result = ag.grade(cf, grade =100, cleanup=False, regrade=True, submissions=[])    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Values\n",
    "No you have graded all the students there is an output file in the /tmp directory with their grades.  The `generate_mangrade` command below will aggregate the values to a CSV file.  \n",
    "\n",
    "This will also match the githubID with the person using the roster file.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate JSON files for manual grading. \n",
    "importlib.reload(ag)\n",
    "mangrade_df=ag.generate_mangrade(cf)\n",
    "mangrade_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Github ID to USERNAME.\n",
    "Currently this is setup to upload to Blackboard.\n",
    "\n",
    "It matches the github name with the student name in the roster file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update Manual Grading to include email, etc. Make sure only run 1 time. \n",
    "github_df=pd.read_excel(cf['roster_path'], sheet_name='github')\n",
    "mangrade_df_updated=mangrade_df.merge(github_df, left_on='github_id', right_on='github_id', how = 'left')\n",
    "mangrade_df_updated=mangrade_df_updated.sort_values(by=['lastname_r','firstname_r'])\n",
    "mangrade_df_updated.to_excel(cf['mangrade_output_path'], sheet_name='mangrade', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading \n",
    "Now go ahead and manually grade all manual questions.\n",
    "\n",
    "Create a column total which includes `autograde_total` plus any manual grading. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Blackboard \n",
    "\n",
    "This will generate a blackboard upload dataframe and message variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the updated grading file. \n",
    "mangrade_df=pd.read_excel(cf['mangrade_output_path'])\n",
    "message_complete = \"\"\"Your submission was successfully received and graded.  The attached result is the score \n",
    "received for each question as well as the output if an error was obtained.  \n",
    "<br>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "message_incomplete = \"\"\"If you get this message see the instructor. \n",
    "\"\"\"\n",
    "github_df=pd.read_excel(cf['roster_path'], sheet_name='github')\n",
    "blackboard_df=pd.read_excel(cf['roster_path'], sheet_name='blackboard')\n",
    "blackboard_df.rename(columns={cf['blackboard_rename_col']: cf['blackboard_total_col']}, inplace=True)\n",
    "blackboard_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Grade to Blackboard CSV\n",
    "This will generate the output `blackboard.csv` file which can be updated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter\n",
    "complete = 0\n",
    "incomplete = 0\n",
    "print(cf['mangrade_match_col'],cf['blackboard_match_col'] )\n",
    "for index, row in blackboard_df.iterrows():\n",
    "    github_id=None\n",
    "    github_id=github_df.loc[github_df['username_r'] == row['Username'],'github_id'].values\n",
    "    if (len(github_id))>0:\n",
    "        github_id=github_id[0]\n",
    "        match_row=mangrade_df.loc[mangrade_df['github_id'] == github_id,]\n",
    "        if len(match_row)>0:\n",
    "            text=\"\"\n",
    "            for x in match_row.columns:\n",
    "                text=text+x+\": \"+str( match_row[x].ravel()[0])+\"<br>\"\n",
    "            blackboard_df.loc[index,cf['blackboard_total_col']]=match_row['total'].ravel()[0]\n",
    "            blackboard_df.loc[index,'Feedback Format']='HTML'\n",
    "            blackboard_df.loc[index,'Feedback to Learner']=message_complete+text\n",
    "            complete =complete+1\n",
    "        else:\n",
    "            incomplete =incomplete+1\n",
    "            blackboard_df.loc[index,cf['blackboard_total_col']]=0\n",
    "            blackboard_df.loc[index,'Feedback to Learner']=message_incomplete\n",
    "            incomplete=incomplete+1\n",
    "    else:\n",
    "        incomplete =incomplete+1\n",
    "        blackboard_df.loc[index,cf['blackboard_total_col']]=0\n",
    "        blackboard_df.loc[index,'Feedback to Learner']=message_incomplete\n",
    "        incomplete=incomplete+1\n",
    "    \n",
    "\n",
    "    #blackboard_df.loc[index,blackboard_total_col]=mangrade_df.loc[mangrade_df[mangrade_match_col] == row[blackboard_match_col],'total'].ravel()[0]\n",
    "blackboard_df.to_csv(cf['blackboard_output_path'], index = False)\n",
    "print(\"complete:\", complete,\"\\nIncomplete:\",incomplete,\"\\nTotal:\",complete+incomplete)\n",
    "blackboard_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the Blackboard File \n",
    "\n",
    "And you are done. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "grade_colab_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:autograding]",
   "language": "python",
   "name": "conda-env-autograding-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
